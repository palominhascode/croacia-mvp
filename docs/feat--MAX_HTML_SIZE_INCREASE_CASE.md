

## Ã‰ possÃ­vel aumentar o gMaxHtmlSize = 50000 em scraper.nim, sem causar problemas?

Sim, Ã© possÃ­vel, mas hÃ¡ trade-offs importantes a considerar:

***

## âš–ï¸ **Trade-offs de Aumentar o HTML Size**

### âœ… **Vantagens:**

- Mais contexto para anÃ¡lise de IA
- Captura pÃ¡ginas maiores/mais complexas
- Melhor para sites com muito conteÃºdo

### âš ï¸ **Desvantagens:**

- **Maior uso de memÃ³ria** (pode causar OOM no Fly.io)
- **LatÃªncia maior** (transfer + processamento)
- **Custo de bandwidth** (Fly.io cobra por GB transferido)
- **Timeout risk** (requests mais lentos)

***

## ðŸ“Š **Limites Recomendados por CenÃ¡rio**

| Tamanho   | Uso Recomendado    | MemÃ³ria/Request | LatÃªncia MÃ©dia |
| --------- | ------------------ | --------------- | -------------- |
| **50KB**  | PadrÃ£o (atual)     | ~200KB          | 2-5s           |
| **100KB** | Sites complexos    | ~400KB          | 3-8s           |
| **200KB** | AnÃ¡lise profunda   | ~800KB          | 5-12s          |
| **500KB** | MÃ¡ximo recomendado | ~2MB            | 10-20s         |
| **1MB+**  | âš ï¸ NÃ£o recomendado | ~4MB+           | 20-40s+        |

***

## ðŸ§® **CÃ¡lculo de Impacto (Fly.io)**

### ConfiguraÃ§Ã£o Atual (Fly.io)

```toml
[vm]
  memory = '1gb'  # 1024 MB
```

### CenÃ¡rios de ConcorrÃªncia

**Com 50KB (atual):**

```
Requests simultÃ¢neos = 1024MB / (0.2MB * 5 URLs) = ~1000 requests
```

**Com 200KB:**

```
Requests simultÃ¢neos = 1024MB / (0.8MB * 5 URLs) = ~250 requests
```

**Com 500KB:**

```
Requests simultÃ¢neos = 1024MB / (2MB * 5 URLs) = ~100 requests
```

***

## âœ… **RecomendaÃ§Ãµes por Caso de Uso**

### 1. **AnÃ¡lise RÃ¡pida de Snippets (atual - 50KB)**

```nim
gMaxHtmlSize = 50000  # Ideal para resumos rÃ¡pidos
```

- âœ… Baixa latÃªncia
- âœ… Alta concorrÃªncia
- âœ… Custo baixo

***

### 2. **AnÃ¡lise de ConteÃºdo Completo (100KB)**

```nim
gMaxHtmlSize = 100000  # Bom equilÃ­brio
```

- âœ… Captura a maioria das pÃ¡ginas
- âœ… ConcorrÃªncia razoÃ¡vel
- âš ï¸ +50% custo de bandwidth

**Quando usar:**

- Sites de notÃ­cias/blogs
- PÃ¡ginas de produto detalhadas
- Landing pages

***

### 3. **AnÃ¡lise Profunda/SEO (200KB)**

```nim
gMaxHtmlSize = 200000  # Para anÃ¡lise tÃ©cnica
```

- âœ… Captura scripts, CSS inline, JSON-LD
- âš ï¸ LatÃªncia maior
- âš ï¸ ConcorrÃªncia reduzida

**Quando usar:**

- AnÃ¡lise de SEO tÃ©cnico
- ExtraÃ§Ã£o de structured data
- Sites com muito JavaScript

***

### 4. **PÃ¡ginas Muito Grandes (500KB - MÃ¡ximo)**

```nim
gMaxHtmlSize = 500000  # Apenas se necessÃ¡rio
```

- âš ï¸ Alto uso de memÃ³ria
- âš ï¸ LatÃªncia significativa
- âš ï¸ Risco de timeout

**Quando usar:**

- Sites de e-commerce (muitos produtos)
- Portais governamentais
- DocumentaÃ§Ã£o tÃ©cnica extensa

***

## ðŸŽ¯ **SoluÃ§Ã£o Recomendada: ParÃ¢metro DinÃ¢mico**

Em vez de fixo, permita configurar por request:

### **AtualizaÃ§Ã£o no `scraper.nim`:**

```nim
# ConfiguraÃ§Ã£o com padrÃ£o flexÃ­vel
proc initializeSecrets*() =
  echo "[INIT] âœ“ Carregando secrets do ambiente..."

  gSerperApiKey = getEnv("SERPER_API_KEY", "")
  gSerperApiUrl = "https://google.serper.dev/search"

  # Ler do env com padrÃ£o de 50KB
  let htmlSizeStr = getEnv("MAX_HTML_SIZE", "50000")
  try:
    gMaxHtmlSize = parseInt(htmlSizeStr)
  except:
    gMaxHtmlSize = 50000

  echo "[INIT] âœ“ Max HTML Size: ", gMaxHtmlSize, " bytes"

  # ValidaÃ§Ãµes...
```

### **AtualizaÃ§Ã£o no `scrapePage`:**

```nim
proc scrapePage*(url: string, maxHtmlSize: int = 0): Future[ScrapedResult] {.async, gcsafe.} =
  # ... cÃ³digo existente ...

  var cleanHtml = html

  # Usar tamanho customizado ou padrÃ£o
  let effectiveMaxSize = if maxHtmlSize > 0: maxHtmlSize else: MAX_HTML_SIZE()

  if cleanHtml.len > effectiveMaxSize:
    cleanHtml = cleanHtml[0..<effectiveMaxSize]

  scraped.html = cleanHtml
  # ... resto do cÃ³digo ...
```

### **AtualizaÃ§Ã£o no endpoint `/analyze`:**

```nim
  post "/analyze":
    try:
      let body = request.body
      let params = parseJson(body)

      # ParÃ¢metros existentes...
      let query = params{"query"}.getStr("test")
      let maxResults = if params.hasKey("max_results"):
        params{"max_results"}.getInt(5)
      else:
        5

      # NOVO: Tamanho de HTML customizado
      let htmlSize = if params.hasKey("html_size"):
        min(params{"html_size"}.getInt(50000), 500000)  # Max 500KB
      else:
        50000  # PadrÃ£o

      echo "[API] Query: ", query, " | HTML Size: ", htmlSize

      # Passar para analyzeKeyword...
```

***

## ðŸ§ª **Teste de Capacidade**

Antes de aumentar em produÃ§Ã£o, teste localmente:

```bash
# Terminal 1: Rodar app local
docker run -p 8080:8080 -e SERPER_API_KEY=sua_chave -e MAX_HTML_SIZE=200000 croacia-test

# Terminal 2: Teste de carga
for i in {1..10}; do
  curl -X POST http://localhost:8080/analyze \
    -H "Content-Type: application/json" \
    -d '{"query":"test","max_results":5}' &
done
wait

# Monitorar memÃ³ria
docker stats
```

***

## ðŸ“‹ **Checklist de DecisÃ£o**

Pergunte-se:

- [ ] **Preciso REALMENTE de mais HTML?** (analise seu caso de uso)
- [ ] **A IA consegue processar >50KB eficientemente?**
- [ ] **Posso pagar a latÃªncia extra?** (+50-200% tempo)
- [ ] **Tenho trÃ¡fego baixo?** (<100 req/hora = OK aumentar)
- [ ] **Posso escalar vertical no Fly.io?** (2GB RAM se necessÃ¡rio)

***

## ðŸŽ¯ **Minha RecomendaÃ§Ã£o Final**

**Para seu caso (Toqan custom tool):**

```nim
gMaxHtmlSize = 100000  # 100KB - Sweet spot
```

**Por quÃª:**

- âœ… Dobra o contexto sem muito impacto
- âœ… Captura 95% das pÃ¡ginas comerciais
- âœ… Ainda permite boa concorrÃªncia
- âœ… LatÃªncia aceitÃ¡vel (<8s)

**Se precisar de mais:**

- Implemente o parÃ¢metro dinÃ¢mico `html_size` no request
- Configure 500KB no Fly.io como variÃ¡vel de ambiente
- Monitore uso de memÃ³ria nos logs

***

**Quer que eu forneÃ§a o cÃ³digo completo com o parÃ¢metro dinÃ¢mico?** ðŸš€
